





import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import phik

from scipy.stats import mannwhitneyu

from sklearn.model_selection import (
    RandomizedSearchCV,
    ParameterGrid,
    train_test_split
)
from sklearn.preprocessing import (
    OneHotEncoder,
    StandardScaler,
    MinMaxScaler
)
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.metrics import (
    accuracy_score,
    roc_auc_score,
    recall_score,
    precision_score,
    confusion_matrix
)
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier





test_data_path = os.path.join('data', 'heart_test.csv')
test_data = pd.read_csv(test_data_path)
print(test_data.head(3))


train_data_path = os.path.join('data', 'heart_train.csv')
train_data = pd.read_csv(train_data_path)
print(train_data.head(3))








print(train_data.info())





# сформируем таблицу с анализом пропущенных значений по признакам
missing_info = {
    'feature': [],
    'num_NA': [],
    'frac_NA_perc': []
}

total_rows = train_data.shape[0]

for col in train_data.columns:
    num_na = train_data[col].isna().sum()
    missing_info['feature'].append(col)
    missing_info['num_NA'].append(num_na)
    missing_info['frac_NA_perc'].append(round(num_na / total_rows * 100, 2))

missing_df = pd.DataFrame(missing_info)
missing_df = missing_df.loc[missing_df['num_NA'] != 0]
print(missing_df)





# удаляем признак 'Unnamed: 0'
train_data = train_data.drop('Unnamed: 0', axis=1)

# переносим 'id' в индекс
train_data = train_data.set_index('id', drop=True)

# переименуем столбцы в 'camel_case'
def to_camel_type(string):
    return ['_'.join(w.lower().replace('-', '').split()) for w in string]

train_data.columns = to_camel_type(train_data.columns)

# осуществим замену бинарного категориального признака 'gender' на "1 / 0"
train_data['gender'] = train_data['gender'].map({'Male': 1, 'Female': 0, '1.0':1, '0.0': 0})
#train_data = train_data.loc[train_data['gender'].isin(['Male', 'Female'])]
#train_data['gender'] = train_data['gender'].map({'Male': 1, 'Female': 0})

# переименуем название таргета
train_data.rename(columns={'heart_attack_risk_(binary)': 'heart_attack_risk'}, inplace=True)





# ключевые статистики
display(train_data.describe().T)


# анализ уникальных значений признаков
train_data_info = {
    'name': [],
    'nunique': [],
    'unique_value': []
}

for col in train_data.columns:
    train_data_info['name'].append(col)
    train_data_info['nunique'].append(train_data[col].nunique())
    train_data_info['unique_value'].append(train_data[col].unique())

train_data_info = pd.DataFrame(train_data_info).sort_values(by='nunique', ascending=False)
train_data_info





# составим список категориальных признаков
cat_col = list(train_data_info.loc[train_data_info['nunique'] < 11, 'name'])





missing_cols = [col for col in train_data.columns if train_data[col].isna().sum() > 0]
target_unique = train_data['heart_attack_risk'].unique()

for col in missing_cols:
    for t in target_unique:      
        if col in cat_col:
            na_plug = train_data[train_data['heart_attack_risk'] == t][col].mode()[0]
        else:
            na_plug = train_data[train_data['heart_attack_risk'] == t][col].mean()
        mask = (train_data[col].isna()) & (train_data['heart_attack_risk'] == t)
        train_data.loc[mask, col] = na_plug


# удаляем явные дубликаты
train_data = train_data.drop_duplicates()





print(test_data.info())





# удаляем признак 'Unnamed: 0'
test_data = test_data.drop('Unnamed: 0', axis=1)

# переносим 'id' в индекс
test_data = test_data.set_index('id', drop=True)

# переименуем столбцы в 'camel_case'
test_data.columns = to_camel_type(test_data.columns)

# осуществим замену бинарного категориального признака 'gender' на "1 / 0"
test_data['gender'] = test_data['gender'].map({'Male': 1, 'Female': 0, '1.0':1, '0.0': 0})
#test_data = test_data.loc[test_data['gender'].isin(['Male', 'Female'])]
#test_data['gender'] = test_data['gender'].map({'Male': 1, 'Female': 0})

# удалим пропущенные значения (в связи с тем, что отсутствует таргет)
test_data = test_data.dropna()

# удаляем явные дубликаты
test_data = test_data.drop_duplicates()

















print(f"Сравнение средних значений признаков в разрезе таргета:")
analyse = train_data.groupby('heart_attack_risk').agg(['mean']).T
display(analyse)
print()
print(f"Сравнение дисперсии значений признаков в разрезе таргета:")
analyse = train_data.groupby('heart_attack_risk').agg(['std']).T
display(analyse)





output_df = {
    'feature': [],
    'Mann–Whitney (p-value)': [],
    'p-value < 0.05': []
}

for col in [col for col in train_data.columns if col != 'heart_attack_risk']:
    group0 = train_data[train_data['heart_attack_risk']==0][col]
    group1 = train_data[train_data['heart_attack_risk']==1][col]
    stat, p = mannwhitneyu(group0, group1)
    output_df['feature'].append(col)
    output_df['Mann–Whitney (p-value)'].append(p)
    output_df['p-value < 0.05'].append(0)
    
    
output_df = pd.DataFrame(output_df)
output_df['p-value < 0.05'] = output_df['Mann–Whitney (p-value)'].apply(lambda p: True if p < .05 else False)
output_df = output_df.loc[output_df['p-value < 0.05'] == True].sort_values(by='Mann–Whitney (p-value)').reset_index(drop=True)
output_df.index = output_df.index + 1
sing_feature = list(output_df['feature']) # список значимых признаков согласно тесту
display(output_df)








# функция отрисовки графика
def complex_plot_cont(data, xlabel_def):
    # данные для графика
    data1 = data.query('heart_attack_risk==1')[xlabel_def]
    data2 = data.query('heart_attack_risk==0')[xlabel_def]
    
    # создаем фигуру с двумя колонками: левая — KDE, правая — боксплоты
    fig, axes = plt.subplots(1, 2, figsize=(8, 4), gridspec_kw={'width_ratios': [3, 1]})
    
    # KDE для train и test
    sns.kdeplot(data1, label='target is True', fill=True, alpha=0.5, ax=axes[0])
    sns.kdeplot(data2, label='target is False', fill=True, alpha=0.5, ax=axes[0])
    axes[0].legend()
    axes[0].set_title(f'Сравнение распределений: {xlabel_def}')
    axes[0].set_xlabel('Значения')
    axes[0].set_ylabel('Плотность')
    
    # боксплоты для train и test
    box_data = pd.DataFrame({
        xlabel_def: pd.concat([data1, data2], ignore_index=True),
        'type': ['True'] * len(data1) + ['False'] * len(data2)
    })
    sns.boxplot(x='type', y=xlabel_def, data=box_data, ax=axes[1])
    axes[1].set_title('Анализ выбросов')
    axes[1].set_xlabel('')
    axes[1].set_ylabel('')

    #plt.tight_layout()
    plt.show()


# отрисовка распределений и боксплотов в
col_num = train_data.select_dtypes(include=['number']).columns.tolist()
col_num = [col for col in col_num if col not in ["heart_attack_risk"]]

for col_i in col_num:
    complex_plot_cont(train_data, col_i)





# проведем анализ уникальных значений признаков
features_check = ['blood_sugar', 'ckmb', 'troponin']
for col in features_check:
    print(train_data[col].value_counts(normalize=True).head(3))
    print(f"дисперсия = {train_data[col].std():.4f}")
    print() 


train_data['blood_sugar'].value_counts()





# проанализируем значения признака 'heart_rate'
train_data['heart_rate'].sort_values(ascending=False).head(5)





train_data = train_data.loc[~(train_data['heart_rate']==1)]











# разделим общий датасет на тренировочную и тестовую выборки
train_df = train_data.copy()
col_num = list(set(train_df.columns) - set(cat_col))
# рассчитаем корреляции признаков
print('Тренировочная выборка:\n')
cor_matrix = train_df.phik_matrix(interval_cols=col_num)
corr_df = pd.DataFrame(cor_matrix,
                       index = train_df.columns, 
                       columns=train_df.columns)
ax, fig = plt.subplots(figsize=(12, 12))
ax=sns.heatmap(corr_df, annot=True, annot_kws={"size": 6}, fmt='.2f')
ax.set_title('Корреляционная матрица (Фи)')
plt.show()





























exclude_list = ['sedentary_hours_per_day', 'physical_activity_days_per_week',
                'bmi', 'medication_use', 'previous_heart_problems', 'diet', 'income',
                'ckmb', 'troponin', 'blood_sugar', 'exercise_hours_per_week']
train_data = train_data.drop(exclude_list, axis=1)
test_data = test_data.drop(exclude_list, axis=1)











RANDOM_STATE = 42

# данные для моделирования
X_train, X_test, y_train, y_test = train_test_split(
    train_data.drop(['heart_attack_risk'], axis=1),
    train_data.copy()['heart_attack_risk'],
    test_size = 0.25,
    random_state = RANDOM_STATE,
    stratify = train_data['heart_attack_risk']
)

# списки с названиями признаков
ohe_columns =[
    'diabetes', 'family_history', 'smoking', 'obesity', 'alcohol_consumption',   
    'stress_level', 'sleep_hours_per_day', 'gender'
]

num_columns = [
    'age', 'cholesterol', 'heart_rate', 'triglycerides', 
    'systolic_blood_pressure', 'diastolic_blood_pressure'
]


# создаем пайплайн для подготовки признаков из списка ohe_columns
ohe_pipe = Pipeline(
    [
        ('simpleImputer_ohe', SimpleImputer(missing_values=np.nan, strategy='most_frequent')),
        ('ohe', OneHotEncoder(drop='first', handle_unknown='error', sparse_output=False))
    ]
)

num_pipe = Pipeline(
    [
        ('simpleImputer_num', SimpleImputer(missing_values=np.nan, strategy='most_frequent')),
        ('num', 'passthrough')
    ]
)

# создаем общий пайплайн для подготовки данных
data_preprocessor = ColumnTransformer(
    [
        ('ohe', ohe_pipe, ohe_columns),
        ('num', num_pipe, num_columns)
    ],
    remainder='passthrough'
)

# создаем итоговый пайплайн 
pipe_final = Pipeline(
    [
        ('preprocessor', data_preprocessor),
        ('models', DecisionTreeClassifier(random_state=RANDOM_STATE))
    ]
)





pipe_final = Pipeline(
    [
        ('preprocessor', data_preprocessor),
        ('models', DecisionTreeClassifier(random_state=RANDOM_STATE))
    ]
)


# создаем список словарей моделей и гиперпараметров для перебора
param_grid = [
    # словарь для KNN
    {
        'models': [KNeighborsClassifier()],
        'models__weights': ['uniform', 'distance'],
        'models__n_neighbors': range(3, 10),
        'preprocessor__num': [StandardScaler(), MinMaxScaler(), 'passthrough']
    },
    
    # словарь для DecisionTreeClassifier
    {
        'models': [DecisionTreeClassifier(random_state=RANDOM_STATE)],
        'models__max_depth': range(2, 10),
        'models__max_features': range(2, 10),
        'preprocessor__num': [StandardScaler(), MinMaxScaler(), 'passthrough']
    },
       
    # словать для SVC
    {
        'models': [SVC(probability=True, random_state=RANDOM_STATE)],
        'models__degree': range(1, 6),
        'models__kernel': ['linear', 'rbf', 'sigmoid', 'poly'],
        'preprocessor__num': [StandardScaler(), MinMaxScaler(), 'passthrough']
    }
]


grid = list(ParameterGrid(param_grid))
print(f"Всего комбинаций: {len(grid)}")  # Выведет 24








# поиск лучшей комбинации "модель-гиперпараметр"
randomized_search = RandomizedSearchCV(
    pipe_final,
    param_grid,
    n_iter=50,
    cv=5,
    scoring=['recall', 'roc_auc', 'f1', 'accuracy'],
    refit='recall',
    random_state=RANDOM_STATE,
    n_jobs=-1,
    verbose=0
).fit(X_train, y_train)


result = pd.DataFrame(randomized_search.cv_results_)
result_sort = result[
    ['mean_fit_time', 'param_models', 'param_preprocessor__num', 'mean_test_recall', 'mean_test_roc_auc', 
     'mean_test_f1', 'mean_test_accuracy',  'rank_test_roc_auc', 'rank_test_recall']
].sort_values('rank_test_recall').reset_index(drop=True)

print('Рейтинг моделей по показателю Recall:')
display(result_sort.head(10))


# лучшая модель
best_estimator = randomized_search.best_estimator_
print('Гиперпараметры лучшей модели:\n')
print(best_estimator)
best_model_class = best_estimator['models']
final_preprocessor = best_estimator['preprocessor']
X_test_transformed = final_preprocessor.transform(X_test)
y_pred = best_model_class.predict(X_test_transformed)





# отрисовка графика
ax = plt.subplot()
lbls = ['нет', 'да']
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, 
            annot=True, fmt='d', cmap='Blues_r')
ax.set_xlabel('y_pred');
ax.set_ylabel('y_test'); 
ax.set_title('Confusion Matrix'); 
ax.xaxis.set_ticklabels(lbls); 
ax.yaxis.set_ticklabels(lbls);
plt.show()
    
# расчет метрик качества
print('\nМетрики качества:')
print(f" Accuracy = {accuracy_score(y_test, y_pred):.2f}")
print(f" Precision = {(cm[1,1] / (cm[1,1] + cm[0,1])):.2f}")
print(f" Recall = {(cm[1,1] / (cm[1,1] + cm[1,0])):.2f}")
print(f" ROC-AUC score: {roc_auc_score(y_test, best_model_class.predict_proba(X_test_transformed)[:,1]):.2f}")











# формула вывода прогноза скорректированной модели:
def predict_with_threshold(model, X_test_data, threshold=0.5):
    prob = model.predict_proba(X_test_data)[:, 1]
    out = pd.Series(prob).apply(lambda x: 1 if x > threshold else 0)
    return out


# функция для вывода показателей:
def model_metrics_def(y_true, y_scenario):
    cm = confusion_matrix(y_true, y_scenario)
    accuracy = accuracy_score(y_true, y_scenario)
    precision = precision_score(y_true, y_scenario, pos_label=1, zero_division=1)
    recall = recall_score(y_true, y_scenario, pos_label=1, zero_division=1)
    return (accuracy, precision, recall)


# функция вывода форматированной матрицы 
def confusion_matrix_def(y_test, y_pred, lbls=['нет', 'да']):
    ax= plt.subplot()
    sns.heatmap(confusion_matrix(y_test, y_pred),
                annot=True, fmt='d', cmap='Blues_r')
    # подписи осей:
    ax.set_xlabel('y_pred');
    ax.set_ylabel('y_test'); 
    ax.set_title('Confusion Matrix'); 
    ax.xaxis.set_ticklabels(lbls); 
    ax.yaxis.set_ticklabels(lbls);
    plt.show()


# выгрузка вероятностей исходной модели:
y_proba = best_model_class.predict_proba(X_test_transformed)[:, 1]

# подготовка данных:
data = pd.DataFrame(zip(y_test, y_proba), columns = ['y_valid', 'y_proba'])

# создание диапазона вариации порога классификации:
thresholds = [round(i, 2) for i in np.arange(0.1, 1, 0.05)]

# заполнение таблицы прогнозов для различных значений порога классификации:
columns = []
for i in thresholds:
    columns.append('y_pred_'+str(i))
    data['y_pred_'+str(i)] = data['y_proba'].apply(lambda x: 1 if x >= i else 0)

# заполним таблицу с метриками:
summary_df = pd.DataFrame(thresholds)
np.zeros((data.shape[1]-2,3))

# заполним таблицу с метриками:
summary_df = pd.DataFrame(thresholds)
metr_matrix = np.zeros((data.shape[1]-2,3))
for i in range(data.shape[1]-2):
    for j in range(3):
        metr_matrix[i, j] = model_metrics_def(data['y_valid'], data.iloc[:, i+2])[j]
        
summary_df = pd.concat([summary_df, pd.DataFrame(metr_matrix)], axis=1)
summary_df.columns = ['thresholds', 'accuracy', 'precision', 'recall']
summary_df


y_pred = predict_with_threshold(best_model_class, X_test_transformed, threshold=0.2)

# отрисовка графика
ax = plt.subplot()
lbls = ['нет', 'да']
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, 
            annot=True, fmt='d', cmap='Blues_r')
ax.set_xlabel('y_pred');
ax.set_ylabel('y_test'); 
ax.set_title('Confusion Matrix'); 
ax.xaxis.set_ticklabels(lbls); 
ax.yaxis.set_ticklabels(lbls);
plt.show()
    
# расчет метрик качества
print('\nМетрики качества:')
print(f" Accuracy = {accuracy_score(y_test, y_pred):.2f}")
print(f" Precision = {(cm[1,1] / (cm[1,1] + cm[0,1])):.2f}")
print(f" Recall = {(cm[1,1] / (cm[1,1] + cm[1,0])):.2f}")
print(f" ROC-AUC score: {roc_auc_score(y_test, best_model_class.predict_proba(X_test_transformed)[:,1]):.2f}")






























